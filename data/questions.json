[
  {
    "id": 1,
    "type": "single",
    "question": "【1】資料倉儲學院(TDWI)將商業智慧(BI)比喻成一個資料煉油廠(Data Refinery)，BI 在資料煉油廠的類比中的資訊處理程序是?",
    "options": [
      "資料→資訊→知識",
      "資料→資訊→智慧",
      "資料→資訊→知識→智慧",
      "資料→資訊→知識→決策"
    ],
    "answer": [
      4
    ],
    "weight": 2,
    "image": null,
    "explanation": "● 決策樹模型：以其直觀的樹狀結構著稱,每一步決策都有清晰的路徑和條件,因此具有良好的可解釋性,適合需要向非技術人員(如醫療技術人員)解釋模型決策過程的場景。\n● 支援向量機和神經網路：通常被視為黑箱模型,解釋性較差。\n● K-Means：是無監督學習的叢集演算法,不適用於建立導引系統(通常是分類或回歸問題)。"
  },
  {
    "id": 2,
    "type": "single",
    "question": "【2】下列何者不是監督式學習的應用?",
    "options": [
      "垃圾郵件分類",
      "房價預測",
      "客戶分群",
      "信用評分"
    ],
    "answer": [
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 監督式學習需要標註資料(有明確的輸入與輸出對應)。\n● 垃圾郵件分類、房價預測、信用評分都是監督式學習的典型應用。\n● 客戶分群屬於非監督式學習,因為沒有預先定義的標籤,系統需要自動發現資料中的模式。"
  },
  {
    "id": 3,
    "type": "multi",
    "question": "【3】下列哪些是深度學習的常見應用?(複選)",
    "options": [
      "圖像識別",
      "自然語言處理",
      "語音識別",
      "線性迴歸"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 深度學習在圖像識別、自然語言處理、語音識別等領域都有廣泛應用。\n● 線性迴歸是傳統的統計學習方法,不屬於深度學習範疇。"
  },
  {
    "id": 4,
    "type": "single",
    "question": "【4】在機器學習中,過擬合(Overfitting)是指?",
    "options": [
      "模型在訓練資料上表現很好,但在測試資料上表現不佳",
      "模型在訓練資料和測試資料上都表現不佳",
      "模型訓練時間過長",
      "模型參數過少"
    ],
    "answer": [
      1
    ],
    "weight": 2,
    "image": null,
    "explanation": "● 過擬合是指模型過度學習了訓練資料的細節和雜訊,導致在新資料上泛化能力差。\n● 典型特徵是訓練準確率很高,但測試準確率較低。\n● 可透過正規化、增加訓練資料、降低模型複雜度等方法來緩解。"
  },
  {
    "id": 5,
    "type": "single",
    "question": "【5】下列何者是強化學習的核心概念?",
    "options": [
      "標註資料",
      "特徵工程",
      "獎勵機制",
      "資料清洗"
    ],
    "answer": [
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 強化學習的核心是透過與環境互動,根據獎勵(Reward)訊號來學習最佳策略。\n● Agent(智能體)透過試錯來最大化累積獎勵。\n● 不需要標註資料,而是透過獎勵訊號來引導學習。"
  },
  {
    "id": 6,
    "type": "multi",
    "question": "【6】下列哪些技術可以用來處理類別不平衡問題?(複選)",
    "options": [
      "過採樣(Over-sampling)",
      "欠採樣(Under-sampling)",
      "SMOTE合成少數類樣本",
      "增加學習率"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 類別不平衡會導致模型偏向多數類。\n● 過採樣：增加少數類樣本數量。\n● 欠採樣：減少多數類樣本數量。\n● SMOTE：合成少數類樣本的技術。\n● 增加學習率與類別不平衡問題無直接關係。"
  },
  {
    "id": 7,
    "type": "single",
    "question": "【7】卷積神經網路(CNN)最常用於處理哪種類型的資料?",
    "options": [
      "表格資料",
      "圖像資料",
      "時間序列資料",
      "文字資料"
    ],
    "answer": [
      2
    ],
    "weight": 1,
    "image": null,
    "explanation": "● CNN透過卷積層能夠有效提取圖像的局部特徵。\n● 具有平移不變性,適合處理圖像識別、物體偵測等任務。\n● 雖然CNN也可用於文字和時間序列,但最主要的應用領域是電腦視覺。"
  },
  {
    "id": 8,
    "type": "single",
    "question": "【8】下列何者是循環神經網路(RNN)的主要優勢?",
    "options": [
      "可以處理序列資料",
      "訓練速度最快",
      "不需要大量資料",
      "模型最簡單"
    ],
    "answer": [
      1
    ],
    "weight": 2,
    "image": null,
    "explanation": "● RNN具有記憶功能,能夠處理序列資料(如文字、語音、時間序列)。\n● 透過隱藏狀態保留歷史資訊。\n● 但RNN訓練較慢且容易出現梯度消失問題。"
  },
  {
    "id": 9,
    "type": "multi",
    "question": "【9】下列哪些是評估分類模型效能的指標?(複選)",
    "options": [
      "準確率(Accuracy)",
      "精確率(Precision)",
      "召回率(Recall)",
      "均方誤差(MSE)"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 準確率、精確率、召回率都是分類問題的評估指標。\n● 準確率 = 正確預測數 / 總樣本數\n● 精確率 = 真陽性 / (真陽性 + 假陽性)\n● 召回率 = 真陽性 / (真陽性 + 假陰性)\n● 均方誤差(MSE)是迴歸問題的評估指標。"
  },
  {
    "id": 10,
    "type": "single",
    "question": "【10】在深度學習中,Dropout技術的主要作用是?",
    "options": [
      "加快訓練速度",
      "防止過擬合",
      "增加模型容量",
      "減少記憶體使用"
    ],
    "answer": [
      2
    ],
    "weight": 2,
    "image": null,
    "explanation": "● Dropout在訓練時隨機丟棄一部分神經元。\n● 迫使網路學習更魯棒的特徵,不依賴特定神經元。\n● 有效防止過擬合,提升模型泛化能力。\n● 相當於訓練多個子網路的集成效果。"
  },
  {
    "id": 11,
    "type": "single",
    "question": "【11】下列何者是遷移學習(Transfer Learning)的主要優勢?",
    "options": [
      "可以在小資料集上取得好結果",
      "訓練時間最短",
      "模型最簡單",
      "不需要GPU"
    ],
    "answer": [
      1
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 遷移學習利用預訓練模型的知識。\n● 在目標任務資料量較少時仍能取得良好效果。\n● 減少訓練時間和計算資源需求。\n● 特別適合電腦視覺和自然語言處理任務。"
  },
  {
    "id": 12,
    "type": "multi",
    "question": "【12】下列哪些是自然語言處理(NLP)的常見任務?(複選)",
    "options": [
      "文本分類",
      "命名實體識別",
      "機器翻譯",
      "圖像分割"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 文本分類：如情感分析、主題分類。\n● 命名實體識別：識別人名、地名、組織名等。\n● 機器翻譯：將文本從一種語言翻譯成另一種語言。\n● 圖像分割屬於電腦視覺任務,不是NLP。"
  },
  {
    "id": 13,
    "type": "single",
    "question": "【13】在機器學習中,交叉驗證(Cross-Validation)的主要目的是?",
    "options": [
      "增加訓練資料",
      "評估模型泛化能力",
      "加快訓練速度",
      "減少特徵數量"
    ],
    "answer": [
      2
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 交叉驗證將資料分成多個子集。\n● 輪流使用不同子集作為驗證集。\n● 更準確地評估模型在未知資料上的表現。\n● 常用的有k折交叉驗證(k-fold CV)。"
  },
  {
    "id": 14,
    "type": "single",
    "question": "【14】下列何者是生成對抗網路(GAN)的主要組成部分?",
    "options": [
      "編碼器和解碼器",
      "生成器和判別器",
      "輸入層和輸出層",
      "卷積層和池化層"
    ],
    "answer": [
      2
    ],
    "weight": 2,
    "image": null,
    "explanation": "● GAN由生成器(Generator)和判別器(Discriminator)組成。\n● 生成器試圖生成逼真的假資料。\n● 判別器試圖區分真實資料和生成資料。\n● 兩者透過對抗訓練不斷進步。"
  },
  {
    "id": 15,
    "type": "multi",
    "question": "【15】下列哪些是降維技術?(複選)",
    "options": [
      "主成分分析(PCA)",
      "t-SNE",
      "自編碼器(Autoencoder)",
      "梯度下降"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● PCA：線性降維方法,尋找資料的主要變異方向。\n● t-SNE：非線性降維方法,常用於視覺化。\n● 自編碼器：透過神經網路進行降維。\n● 梯度下降是優化算法,不是降維技術。"
  },
  {
    "id": 16,
    "type": "single",
    "question": "【16】在深度學習中,批次正規化(Batch Normalization)的主要作用是?",
    "options": [
      "防止過擬合",
      "加速訓練並穩定學習過程",
      "減少參數數量",
      "增加模型深度"
    ],
    "answer": [
      2
    ],
    "weight": 2,
    "image": null,
    "explanation": "● Batch Normalization對每層的輸入進行標準化。\n● 減少內部協變量偏移(Internal Covariate Shift)。\n● 允許使用更高的學習率。\n● 加速訓練收斂,使訓練更穩定。"
  },
  {
    "id": 17,
    "type": "single",
    "question": "【17】下列何者是Transformer模型的核心機制?",
    "options": [
      "卷積運算",
      "循環運算",
      "自注意力機制",
      "池化運算"
    ],
    "answer": [
      3
    ],
    "weight": 2,
    "image": null,
    "explanation": "● Transformer使用自注意力機制(Self-Attention)。\n● 能夠捕捉序列中任意位置之間的依賴關係。\n● 不使用循環或卷積結構。\n● 可以並行處理,訓練效率高。\n● BERT、GPT等模型都基於Transformer架構。"
  },
  {
    "id": 18,
    "type": "multi",
    "question": "【18】下列哪些是優化算法?(複選)",
    "options": [
      "SGD(隨機梯度下降)",
      "Adam",
      "RMSprop",
      "K-Means"
    ],
    "answer": [
      1,
      2,
      3
    ],
    "weight": 1,
    "image": null,
    "explanation": "● SGD、Adam、RMSprop都是訓練神經網路的優化算法。\n● SGD：基礎的梯度下降方法。\n● Adam：結合動量和自適應學習率。\n● RMSprop：自適應學習率方法。\n● K-Means是叢集演算法,不是優化算法。"
  },
  {
    "id": 19,
    "type": "single",
    "question": "【19】在機器學習中,正規化(Regularization)的主要目的是?",
    "options": [
      "加快訓練速度",
      "防止過擬合",
      "增加訓練資料",
      "提高準確率"
    ],
    "answer": [
      2
    ],
    "weight": 1,
    "image": null,
    "explanation": "● 正規化透過懲罰模型複雜度來防止過擬合。\n● L1正規化(Lasso)：可產生稀疏解。\n● L2正規化(Ridge)：限制權重大小。\n● 提升模型在新資料上的泛化能力。"
  },
  {
    "id": 20,
    "type": "single",
    "question": "【20】下列何者是BERT模型的主要訓練任務?",
    "options": [
      "圖像分類",
      "遮罩語言模型(Masked Language Model)",
      "強化學習",
      "時間序列預測"
    ],
    "answer": [
      2
    ],
    "weight": 2,
    "image": null,
    "explanation": "● BERT使用遮罩語言模型(MLM)進行預訓練。\n● 隨機遮罩輸入中的部分詞彙,預測被遮罩的詞。\n● 同時使用下一句預測(NSP)任務。\n● 透過雙向理解文本,獲得更好的語言表徵。"
  }
]